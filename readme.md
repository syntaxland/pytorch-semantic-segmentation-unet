```md
# ğŸ§  PyTorch U-Net Semantic Segmentation (Carvana)

![PyTorch](https://img.shields.io/badge/PyTorch-2.x-ee4c2c?logo=pytorch)
![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python)
![License](https://img.shields.io/badge/License-MIT-green)

A clean and minimal **U-Net implementation in PyTorch** for **binary semantic segmentation**, trained on the **Carvana Image Masking Challenge** dataset.

---

## ğŸ“Œ Features

- âœ… U-Net architecture from scratch
- âœ… Mixed Precision Training (AMP)
- âœ… Dice Score + Pixel Accuracy
- âœ… Albumentations augmentations
- âœ… Automatic checkpoint saving
- âœ… Prediction image export

---

## ğŸ— Project Structure

```

pytorch-semantic-segmentation-unet/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train_images/
â”‚   â”œâ”€â”€ train_masks/
â”‚   â”œâ”€â”€ val_images/
â”‚   â””â”€â”€ val_masks/
â”‚
â”œâ”€â”€ saved_images/          # Saved predictions
â”œâ”€â”€ dataset.py             # Dataset loader
â”œâ”€â”€ model.py               # U-Net architecture
â”œâ”€â”€ train.py               # Training script
â”œâ”€â”€ utils.py               # Helper functions
â””â”€â”€ UNET_architecture.png  # Architecture diagram

```

---

## ğŸ“Š Dataset

This project uses:

**Carvana Image Masking Challenge (Kaggle)**  
https://www.kaggle.com/competitions/carvana-image-masking-challenge/data

### Expected Folder Format

```

data/train_images/xxx.jpg
data/train_masks/xxx_mask.gif

data/val_images/yyy.jpg
data/val_masks/yyy_mask.gif

````

> ğŸ”¹ Masks must follow naming convention:  
> `image_name.jpg â†’ image_name_mask.gif`

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone repo

```bash
git clone <your-repo-url>
cd pytorch-semantic-segmentation-unet
````

### 2ï¸âƒ£ Create virtual environment (optional but recommended)

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Training

Run:

```bash
python train.py
```

During training:

* ğŸ“ˆ Accuracy and Dice score are printed
* ğŸ’¾ Checkpoints saved as `my_checkpoint.pth.tar`
* ğŸ–¼ Predictions saved in `saved_images/`

---

## ğŸ”§ Configuration

You can edit hyperparameters inside `train.py`:

```python
LEARNING_RATE = 1e-4
BATCH_SIZE = 16
NUM_EPOCHS = 3
IMAGE_HEIGHT = 160
IMAGE_WIDTH = 240
```

To resume training:

```python
LOAD_MODEL = True
```

---

## ğŸ“ Model Details

* Architecture: **U-Net**
* Loss: `BCEWithLogitsLoss`
* Output: Binary mask
* Activation (in eval): `sigmoid`
* Threshold: `0.5`
* Metric: Dice Score

---

## ğŸ“· Example Output

After training:

```
saved_images/
â”œâ”€â”€ pred_0.png
â”œâ”€â”€ pred_1.png
â””â”€â”€ ...
```

---

## ğŸ–¥ Device Support

Automatically detects:

```python
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
```

Works on:

* âœ… CPU
* âœ… NVIDIA GPU (CUDA)

---

## ğŸ§  Architecture

See included diagram:

`UNET_architecture.png`

---

## ğŸ“œ License

MIT License â€” free to use and modify.

---

## ğŸ™Œ Credits

Based on U-Net implementation inspired by
Aladdin Persson's Machine Learning Collection.

```

---

